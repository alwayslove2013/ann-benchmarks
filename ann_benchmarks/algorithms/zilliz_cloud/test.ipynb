{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pymilvus import Collection, utility, connections, CollectionSchema, DataType, FieldSchema, MilvusException\n",
    "\n",
    "\n",
    "MILVUS_LOAD_REQS_SIZE = 1.5 * 1024 * 1024\n",
    "METRIC_MAPPING = {\"dot\": \"IP\", \"angular\": \"COSINE\", \"euclidean\": \"L2\"}\n",
    "\n",
    "\n",
    "class ZillizCloud():\n",
    "    def __init__(self, metric, dim, *wargs, **kwargs):\n",
    "        self.dim = dim\n",
    "        metric = METRIC_MAPPING.get(metric, None)\n",
    "        assert metric is not None\n",
    "        self.metric = metric\n",
    "\n",
    "        uri = \"\"\n",
    "        user = \"\"\n",
    "        password = \"\"\n",
    "        self.db_config = dict(uri=uri, user=user, password=password)\n",
    "        connections.connect(**self.db_config, timeout=30)\n",
    "\n",
    "        self.collection_name = \"ann_test_collection\"\n",
    "        if utility.has_collection(self.collection_name):\n",
    "            print(\"collection exsited, drop it\")\n",
    "            utility.drop_collection(self.collection_name)\n",
    "\n",
    "        self._vector_field = \"vector\"\n",
    "        self._index_name = \"index\"\n",
    "        fields = [\n",
    "            FieldSchema(\"primary\", DataType.INT64, is_primary=True),\n",
    "            FieldSchema(self._vector_field, DataType.FLOAT_VECTOR, dim=dim),\n",
    "        ]\n",
    "        print(\"create collection\")\n",
    "        self.col = Collection(\n",
    "            name=self.collection_name,\n",
    "            schema=CollectionSchema(fields),\n",
    "            consistency_level=\"Session\",\n",
    "        )\n",
    "        self._create_index()\n",
    "        connections.disconnect(\"default\")\n",
    "\n",
    "    def _create_index(self):\n",
    "        print(\"create index\")\n",
    "        index_params = {\"metric_type\": self.metric, \"index_type\": \"AUTOINDEX\"}\n",
    "        self.col.create_index(\n",
    "            self._vector_field,\n",
    "            index_params,\n",
    "            index_name=self._index_name,\n",
    "        )\n",
    "\n",
    "    def fit(self, X: np.array):\n",
    "        print(\"train\", X.shape)\n",
    "        connections.connect(**self.db_config, timeout=30)\n",
    "        self.col = Collection(self.collection_name)\n",
    "        batch_size = int(MILVUS_LOAD_REQS_SIZE / (self.dim * 4))\n",
    "\n",
    "        for batch_start_offset in range(0, X.shape[0], batch_size):\n",
    "            batch_end_offset = min(batch_start_offset + batch_size, X.shape[0])\n",
    "            insert_data = [\n",
    "                list(range(batch_start_offset, batch_end_offset)),\n",
    "                X[batch_start_offset:batch_end_offset],\n",
    "            ]\n",
    "            self.col.insert(insert_data)\n",
    "\n",
    "        self._optimize()\n",
    "\n",
    "    def _optimize(self):\n",
    "        self.col.flush()\n",
    "        self._create_index()\n",
    "        print(\"compact\")\n",
    "\n",
    "        utility.wait_for_index_building_complete(self.collection_name)\n",
    "\n",
    "        def wait_index():\n",
    "            while True:\n",
    "                progress = utility.index_building_progress(self.collection_name)\n",
    "                if progress.get(\"pending_index_rows\", -1) == 0:\n",
    "                    break\n",
    "                time.sleep(5)\n",
    "\n",
    "        wait_index()\n",
    "        self.col.compact()\n",
    "        self.col.wait_for_compaction_completed()\n",
    "        wait_index()\n",
    "        \n",
    "        print(\"load\")\n",
    "        self.col.load()\n",
    "\n",
    "    def query(self, q: np.array, n: int):\n",
    "        print(q.shape)\n",
    "        print(n)\n",
    "        search_params = {\"metric_type\": self.metric}\n",
    "        res = self.col.search(\n",
    "            data=[q],\n",
    "            anns_field=self._vector_field,\n",
    "            param=search_params,\n",
    "            limit=n,\n",
    "        )\n",
    "        ret = [result.id for result in res[0]]\n",
    "        return ret\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"zilliz_cloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "dim = 128\n",
    "train_vectors = np.random.rand(n, dim)\n",
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"euclidean\"\n",
    "zilliz = ZillizCloud(metric, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zilliz.fit(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 9\n",
    "test_q = train_vectors[test_id]\n",
    "res = zilliz.query(test_q, 10)\n",
    "print(res[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
